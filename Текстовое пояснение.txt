На первый взгляд задача оказалась не очень сложной, т.к. необходимо было просто получить заголовки и ссылки на видео, забить их в массивы, а потом данные из этих массивов 
передать в excel. 
Необходимо было определить каким образом получать данные с страницы (сначала с главной) - через requests или через Selenium. Немного погуглив, я увидела, что Selenium 
несколько дольше, т.к. тратится время на загрузку страницы, поэтому сначала решила попробовать через requests - выполнить GET запрос главной страницы, далее использовать 
средства библиотеки BeautifulSoup для парсинга данных, использовать инструмент find_all. Я написала код, поместила в массив перечень всех найденных элементов, но при проверке
выяснилось, что массив пуст. Я попробовала использовать разные атрибуты (a,class), однако это не работало.
Я скопировала в отдельный текстовый файл переменную html, полученную в результате работы оператора bs(page,'html.parser'), попробовала разобрать в получившемся коде названия 
видео. Увидела, что там совершенно другие атрибуты, предположила, что поэтому я и не могу их найти и поместить в массив через find_all. 
Снова стала гуглить - выяснила, что если страница имеет динамическую загрузку (а в YouTube) именно такая, то requests не сработает, надо использовать Selenium, потому что 
он дожидается, когда страница вся подгрузится, а потом уже можно получать код, с которым можно работать. 
Через Selenium все прошло успешно, список наконец-то заполнился элементами и я смогла оттуда выделить имена видео и ссылки на них, а также ссылки на каналы. 
На вышеуказанное у меня ушло достаточно много времени, дальше дело пошло быстрее. 
Какое-то время пришлось затратить на то, чтобы выполнить передачу данных в excel - воспользовалась интернетом, импортировала библиотеку openpyxl. 
Далее поняла, что получение данных при заходе на канал необходимо описать в виде функции, т.к. каналов несколько и нет смысла копировать один и тот же код. 
В качестве аргумента функции передала идентификатор канала, т.к. базовый URL остается всегда одинаковый.
Потом поняла, что получение инфы с главной страницы также надо описать в виде функции, т.к. оно выполняется после захода на канал, поэтому будет функция, которая
выполняется внутри другой функции. 
Остановилась я на передаче данных о названиях видео из бокового блока в excel. Небольшая сложность состоит в том, что необходимо открыть файл, найти первую пустую строку и 
заполнять уже после нее, порядок получения номера первой пустой строки также описала.
Что не успела:
- проработать авторизацию: я через ожидания описала действия Selenium по вводу логина, пароля и нажатию кнопок, пробовала запустить, что-то пошло не так и я решила пока
оставить, эти строки закомментированы;
- понять, как, посмотря видео канала получить из бокового блока ссылки на каналы (т.к. в коде страницы как таковые ссылки именно на каналы не выделены, там вся карточка 
боковых видео - одна сплошная гиперссылка, этот href я считала, но это ссылка на видео, а не на канал);
- проработать момент, связанный с передачей в строки excel значений полученных нами списков, т.к. у нас список с индексами 0, 1, 2, 3 и т.д., а строки будут с бОльшими 
значениями (в зависимости от того, с какой начинаются пустые), я пока не продумала, как их сопоставить. 
